---
title: "p8105_hw3_yj2686"
author: "Yiqun Jin"
date: "10/16/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom")) 

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

**Load instacart dataset**

```{r}
data("instacart")
```


**Description of instacart dataset:**

The instacart dataset is an anonymized dataset with over 3 million online grocery orders from more than 200,000 Instacart users. This dataset contains `r nrow(instacart)` observations of products from online orders, and `r ncol(instacart)` variables which are `r names(instacart)`.
Specifically, `r names(instacart)[7]` stands for the order sequence number for this user (1=first, n=nth), ranging from `r range(pull(instacart, order_number))`. `r names(instacart)[8]` stands for the day of the week on which the order was placed. And `r names(instacart)[10]` stands for days since the last order, capped at 30, NA if order_number = 1, ranging from `r range(pull(instacart, days_since_prior_order))`.

**How many aisles are there, and which aisles are the most items ordered from?**

```{r}
instacart %>% 
  group_by(aisle_id, aisle) %>%
  summarize(count = n()) %>%
  arrange(desc(count))
```

**ANSWER:**
There are `134` aisles and the most items ordered from `fresh vegetables`


**Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered.**

```{r fig.width = 9,fig.height = 9}
instacart %>% 
  count(aisle) %>% 
  rename(ordered_num = n) %>% 
  filter(ordered_num > 10000) %>% 
  mutate(
    aisle = fct_reorder(aisle, ordered_num)
  ) %>% 
  ggplot(aes(x = ordered_num, y = aisle)) +
  geom_point() +
  scale_x_continuous(breaks = seq(0,150000,by = 25000)) +
  labs(
    title = "The number of items ordered in each aisle",
    x = "The number of items",
    y = "Aisles",
    caption = "Data from instacart dataset"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
```

**Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits” and the number of times each item is ordered.**

```{r}
instacart %>% 
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  rename(ordered_times = n) %>% 
  mutate(rank = min_rank(desc(ordered_times))) %>% 
  filter(rank < 4) %>% 
  relocate(aisle, rank) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

**Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week:**

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  mutate(order_dow = ifelse(order_dow == 0, "Sunday", order_dow),
         order_dow = ifelse(order_dow == 1, "Monday", order_dow),
         order_dow = ifelse(order_dow == 2, "Tuesday", order_dow),
         order_dow = ifelse(order_dow == 3, "Wednesday", order_dow),
         order_dow = ifelse(order_dow == 4, "Thursday", order_dow),
         order_dow = ifelse(order_dow == 5, "Friday", order_dow),
         order_dow = ifelse(order_dow == 6, "Saturday", order_dow)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable()
```
  
## Problem 2

**Load BRFSS dataset**

```{r}
data("brfss_smart2010")
```

**Data Cleaning**

```{r}
brfss_df = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  separate(locationdesc, into = c("state", "location"), sep = ' - ') %>% 
  filter(topic == c("Overall Health")) %>% 
  mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"),ordered = TRUE)) %>% 
  arrange(response) %>% 
  select(-locationabbr)
```

**In 2002, which states were observed at 7 or more locations?**

```{r}
brfss_2002 = brfss_df %>% 
  filter(year == 2002) %>% 
  group_by(state) %>% 
  distinct(location) %>% 
  count(state) %>% 
  filter(n >= 7)

brfss_2002
```

**ANSWER:**
`r brfss_2002$state` were observed at 7 or more locations in 2002.

**What about in 2010?**

```{r}
brfss_2010 = brfss_df %>% 
  filter(year == 2010) %>% 
  group_by(state) %>% 
  distinct(location) %>% 
  count(state) %>% 
  filter(n >= 7)

brfss_2010
```

**ANSWER:** 
`r brfss_2010$state` were observed at 7 or more locations in 2010.

**Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state.**

```{r}
excellent_df = brfss_df %>%
  filter(response == "Excellent") %>% 
  group_by(state, year) %>% 
  summarize(mean_data_value = mean(data_value, na.rm = TRUE))
excellent_df
```

**Make a “spaghetti” plot of the average value over time within a state.**

```{r fig.width = 10, fig.height = 10}
excellent_df %>% 
  ggplot(aes(x = year, y = mean_data_value, color = state)) +
  geom_line(alpha = .5, aes(group = state, color = state)) +
  geom_point(alpha = .5, aes(group = state, color = state)) +
  labs(
    title = "Average data value of Excellent responses over time in different states",
    x = "Year",
    y = "Mean data value of Excellent responses",
    caption = "Data from brfss_smart2010"
  ) +
  theme(legend.position = "right",
        plot.title = element_text(hjust = 0.5))
```

**Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.**

```{r}
NY_distribution = brfss_df %>% 
  filter(year %in% c(2006, 2010),
         state == "NY") %>% 
  group_by(year, response) %>% 
  summarize(average_data_value = mean(data_value, na.rm = TRUE)) 

NY_distribution %>% 
  ggplot(aes(x = response, y = average_data_value, fill = response)) +
  geom_col(position = "dodge") +
  facet_grid(. ~ year) +
  labs(
    title = "Distribution of data value for responses among locations in NY State",
    x = "responses among locations in NY State",
    y = "Mean data value",
    caption = "Data from brfss_smart2010"
  )
```

## Problem 3

**Load and tidy Data**

```{r}
accel_df = read.csv("./accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols = activity_1:activity_1440,
    names_to = "minute",
    values_to = "activity_counts",
    names_prefix = "activity_"
  ) %>% 
  mutate(
    weekend_or_weekday = if_else((day == "Saturday" | day == "Sunday"),"Weekend","Weekday"),
    minute = as.numeric(minute),
    day = factor(day, level = c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday")),
    weekend_or_weekday = factor(weekend_or_weekday, level = c("Weekday", "Weekend"))
  ) %>% 
  relocate(week,day_id, day,weekend_or_weekday)


accel_df
```
**Describe the resulting dataset:**

The accel_df dataset contains five weeks of accelerometer data collected on a 63 year-old male with BMI 25, who was admitted to the Advanced Cardiac Care Center of Columbia University Medical Center and diagnosed with congestive heart failure (CHF). 
The accel_df dataset contains `r nrow(accel_df)` observations of activity (accelerometer data), and there are `r ncol(accel_df)` variables, which are `r names(accel_df)` that describing the information of data. Specifically, `r names(accel_df)[5]` stands for the number of minute of a 24-hour day starting at midnight, range from `r range(pull(accel_df, minute))` minutes. And `r names(accel_df)[6]` stands for the activity count of the male collected by accelerometer, ranging from `r range(pull(accel_df, activity_counts))`.

**Aggregate across minutes to create a total activity variable for each day, and create a table showing these totals.**

```{r}
total_activity_df = accel_df %>% 
  group_by(day_id) %>% 
  summarize(total_activity = sum(activity_counts)) 

knitr::kable(total_activity_df)
```

**Are any trends apparent?**

```{r}
ggplot(total_activity_df,aes(x = day_id, y = total_activity)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Trend for total activity counts for each day in five weeks",
    x = "Day ID",
    y = "Total Activity counts",
    caption = "Data from accel_data.csv"
  ) +
  scale_x_continuous(breaks = seq(0,35,by = 5)) +
  theme(plot.title = element_text(hjust = 0.5))
```

**ANSWER:**

The trend of total activity counts for each day is dramatically changed over time in five weeks.

**Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week.**

```{r fig.width = 10, fig.height = 9}
accel_df %>% 
  ggplot(aes(x = minute, y = activity_counts, color = day)) +
  geom_point() +
  geom_line(alpha = .3) +
  scale_x_continuous(breaks = seq(0,1440,by = 60),
                     label = seq(0,24,by = 1),
                     limits = c(0,1440)) +
  labs(
    title = "24-hour activity time courses for each day of the week",
    x = "Hours",
    y = "Activity counts",
    caption = "Data from accel_data.csv"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
```

**Describe the pattern of the graph:**

This 63 year-old male typically start activity at around 7 AM. The activity counts between 11 AM to 12 AM and 16 PM to 17 PM increased during weekend (Saturday and Sunday). There is a large increase in activity counts between 20 PM to 22 PM for most of the days in week (especially on Friday). And this male tend to sleep at around 22 PM.


